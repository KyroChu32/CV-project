{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d5e523",
   "metadata": {},
   "source": [
    "# TCV 3151 ‚Äì Computer Vision Lab (Practical Test)\n",
    "## CIFAR-100 Classification (Classes 61-70)\n",
    "## Optimized for High Accuracy on Small Images\n",
    "\n",
    "**Classes:** plain, plate, poppy, porcupine, possum, rabbit, raccoon, ray, road, rocket\n",
    "\n",
    "‚ö° **Key Strategy:** Custom CNN architecture specifically designed for 32√ó32 CIFAR images\n",
    "üí° **Why not ResNet50?** ResNet is designed for 224√ó224 ImageNet images and performs poorly on 32√ó32 images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b3ee5",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9c5c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "GPU Available: False\n",
      "TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Dense, Dropout, \n",
    "    Flatten, BatchNormalization, Activation\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f67b4",
   "metadata": {},
   "source": [
    "## Section 2: Load and Prepare CIFAR-100 Dataset (Classes 61-70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Dataset configuration\n",
    "DATA_DIR = 'Public_dataset'\n",
    "CLASS_NAMES = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])\n",
    "IMG_SIZE = 512  # Resize images to 512x512\n",
    "\n",
    "print(f\"Class Names: {CLASS_NAMES}\")\n",
    "print(f\"Number of classes: {len(CLASS_NAMES)}\")\n",
    "\n",
    "# Load images from directories\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "    class_dir = os.path.join(DATA_DIR, class_name)\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        if img_file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "                images.append(np.array(img))\n",
    "                labels.append(class_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error loading {img_path}: {e}\")\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset Loaded Successfully!\")\n",
    "print(f\"Total samples: {len(images)}\")\n",
    "print(f\"Image shape: {images[0].shape}\")\n",
    "print(f\"Label distribution:\")\n",
    "for idx, class_name in enumerate(CLASS_NAMES):\n",
    "    count = (labels == idx).sum()\n",
    "    print(f\"  {class_name}: {count} samples\")\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_filtered, x_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {x_train_filtered.shape[0]}\")\n",
    "print(f\"Test samples: {x_test_filtered.shape[0]}\")\n",
    "\n",
    "# For compatibility with existing code\n",
    "y_train_mapped = y_train_filtered\n",
    "y_test_mapped = y_test_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into 90% train and 10% validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_final, x_valid, y_train_final, y_valid = train_test_split(\n",
    "    x_train_filtered, y_train_mapped, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Final Data Split:\")\n",
    "print(f\"Training: {x_train_final.shape[0]} samples\")\n",
    "print(f\"Validation: {x_valid.shape[0]} samples\")\n",
    "print(f\"Test: {x_test_filtered.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66dd832",
   "metadata": {},
   "source": [
    "## Section 3: Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization: Scale pixel values to [0, 1]\n",
    "x_train_norm = x_train_final.astype('float32') / 255.0\n",
    "x_valid_norm = x_valid.astype('float32') / 255.0\n",
    "x_test_norm = x_test_filtered.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_onehot = to_categorical(y_train_final, 10)\n",
    "y_valid_onehot = to_categorical(y_valid, 10)\n",
    "y_test_onehot = to_categorical(y_test_mapped, 10)\n",
    "\n",
    "print(\"‚úÖ Data normalized and labels one-hot encoded!\")\n",
    "print(f\"Training labels shape: {y_train_onehot.shape}\")\n",
    "print(f\"Validation labels shape: {y_valid_onehot.shape}\")\n",
    "print(f\"Test labels shape: {y_test_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stronger Data Augmentation for better generalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,           # Random rotation\n",
    "    horizontal_flip=True,        # Horizontal flip\n",
    "    width_shift_range=0.1,       # Horizontal shift\n",
    "    height_shift_range=0.1,      # Vertical shift\n",
    "    zoom_range=0.1,              # Zoom\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit augmentation on training data\n",
    "datagen.fit(x_train_norm)\n",
    "\n",
    "print(\"‚úÖ Data augmentation configured!\")\n",
    "print(\"   Transformations: rotation, flip, shift, zoom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d62b6",
   "metadata": {},
   "source": [
    "## Section 4: Build Custom CNN (Optimized for CIFAR 32√ó32 Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da1299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Custom CNN Architecture (VGG-style for Public_dataset)\n",
    "model = Sequential([\n",
    "    # Block 1\n",
    "    Conv2D(64, (3, 3), padding='same', input_shape=(512, 512, 3)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(64, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Block 2\n",
    "    Conv2D(128, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(128, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Block 3\n",
    "    Conv2D(256, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(256, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(256, (3, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # Classifier\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "print(\"‚úÖ Custom CNN built successfully!\")\n",
    "print(f\"   Total parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15abc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with Adam optimizer\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # Good starting LR for custom CNN\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model compiled successfully!\")\n",
    "print(\"\\nüìã Model Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14daec5",
   "metadata": {},
   "source": [
    "## Section 5: Train Model with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8721cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback 1: Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',         # Monitor validation accuracy\n",
    "    patience=10,                    # Wait 10 epochs before stopping\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Callback 2: Reduce Learning Rate on Plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,                     # Reduce LR by half\n",
    "    patience=5,                     # After 5 epochs with no improvement\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train with data augmentation\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train_norm, y_train_onehot, batch_size=128),\n",
    "    epochs=50,                      # Max 50 epochs (will stop early)\n",
    "    validation_data=(x_valid_norm, y_valid_onehot),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34014523",
   "metadata": {},
   "source": [
    "## Section 6: Evaluate and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training/validation curves\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "plt.title('Model Accuracy (Train vs Validation)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "plt.title('Model Loss (Train vs Validation)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training curves plotted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ff103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test_onehot, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TEST SET EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Loss:     {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for confusion matrix\n",
    "y_pred_probs = model.predict(x_test_norm, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_test_true = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - CIFAR-100 Classes 61-70', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion Matrix plotted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b67b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test_true, y_pred, target_names=CLASS_NAMES))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63293c",
   "metadata": {},
   "source": [
    "## Summary & Key Insights\n",
    "\n",
    "### üéØ Approach Used:\n",
    "- **Custom CNN Architecture** - VGG-style network designed specifically for 32√ó32 images\n",
    "- **BatchNormalization** - Stabilizes training and allows higher learning rates\n",
    "- **Progressive Dropout** - 0.2 ‚Üí 0.3 ‚Üí 0.4 ‚Üí 0.5 to prevent overfitting\n",
    "- **Data Augmentation** - Rotation, flips, shifts, zoom for better generalization\n",
    "- **Smart Callbacks** - Early stopping + learning rate reduction\n",
    "\n",
    "### üí° Why This Works Better Than ResNet50:\n",
    "1. **Scale Mismatch:** ResNet50 is designed for 224√ó224 ImageNet images. On 32√ó32 CIFAR images, its deep layers and downsampling destroy critical features\n",
    "2. **Parameter Efficiency:** Custom CNN has ~2-3M parameters vs ResNet50's 25M+ parameters\n",
    "3. **Proper Feature Extraction:** Shallow network preserves spatial information crucial for small images\n",
    "4. **Tailored Architecture:** 3 conv blocks match CIFAR's image resolution perfectly\n",
    "\n",
    "### üìà Expected Performance:\n",
    "- **Training Time:** 20-35 minutes (M4 GPU)\n",
    "- **Test Accuracy:** 85-92% (vs 10-20% with ResNet50)\n",
    "- **Epochs to Convergence:** 20-35 (with early stopping)\n",
    "\n",
    "### ‚úÖ Key Improvements Over ResNet Approach:\n",
    "- ‚úÖ Proper architecture for 32√ó32 images\n",
    "- ‚úÖ BatchNormalization for stable training\n",
    "- ‚úÖ L2 regularization to prevent overfitting\n",
    "- ‚úÖ Learning rate scheduling\n",
    "- ‚úÖ Better accuracy monitoring (val_accuracy instead of val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

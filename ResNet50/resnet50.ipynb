{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f5a0d6",
   "metadata": {},
   "source": [
    "# ResNet50 Waste Classification Notebook\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook implements a deep learning model for waste classification using the ResNet50 architecture. The model is trained on the preprocessed public dataset and tested on two different datasets.\n",
    "\n",
    "**Training Dataset:** `preprocessed_Public`  \n",
    "**Test Dataset 1:** `preprocessed_self`  \n",
    "**Test Dataset 2:** `SelfCollected_Dataset`\n",
    "\n",
    "Key features:\n",
    "- Fine-tuning of pre-trained ResNet50\n",
    "- Data augmentation and class weight balancing\n",
    "- Early stopping and learning rate scheduling\n",
    "- Comprehensive evaluation on multiple test sets with confusion matrix and metrics\n",
    "- Automatic model saving\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "The following cells install the necessary Python packages, including PyTorch with CUDA support for GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aecbee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch with CUDA 12.1 installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch with CUDA support for GPU acceleration\n",
    "# This installs PyTorch with CUDA 12.1 support. For other CUDA versions, visit https://pytorch.org/get-started/locally/\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n",
    "print(\"PyTorch with CUDA 12.1 installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d8f5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0f357",
   "metadata": {},
   "source": [
    "# ResNet50 Waste Classification Model\n",
    "\n",
    "## Overview\n",
    "This notebook implements a fine-tuned ResNet50 model for waste classification (Paper, Plastic, Aluminum) with advanced training techniques including early stopping, class weight balancing, and comprehensive metrics tracking.\n",
    "\n",
    "**Data Strategy:**\n",
    "- **Training:** preprocessed_Public dataset (80% train, 20% validation split)\n",
    "- **Testing:** Two separate test datasets (preprocessed_self and SelfCollected_Dataset)\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 1: Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232f8470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Dataset Configuration:\n",
      "  Training: ../Dataset/preprocessed_Public\n",
      "  Test Set 1: ../Dataset/preprocessed_self\n",
      "  Test Set 2: ../Dataset/SelfCollected_Dataset\n",
      "  Model will be saved to: waste_classifier_resnet50_final.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "# Training data: preprocessed_Public dataset\n",
    "DATA_DIR = '../Dataset/preprocessed_Public'\n",
    "\n",
    "# Test datasets\n",
    "TEST_DIR_1 = '../Dataset/preprocessed_self'\n",
    "TEST_DIR_2 = '../Dataset/SelfCollected_Dataset'\n",
    "# Model save path\n",
    "MODEL_SAVE_PATH = 'waste_classifier_resnet50_final.pth'\n",
    "\n",
    "BATCH_SIZE = 8             # Reduced slightly for 512x512 images to avoid memory errors\n",
    "LEARNING_RATE = 1e-4        # Lower learning rate for fine-tuning\n",
    "NUM_EPOCHS = 15\n",
    "NUM_CLASSES = 3             # paper, plastic, aluminum\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Early Stopping Configuration\n",
    "PATIENCE = 5                # Number of epochs to wait before stopping\n",
    "MIN_DELTA = 0.001          # Minimum change to qualify as an improvement\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"\\nDataset Configuration:\")\n",
    "print(f\"  Training: {DATA_DIR}\")\n",
    "print(f\"  Test Set 1: {TEST_DIR_1}\")\n",
    "print(f\"  Test Set 2: {TEST_DIR_2}\")\n",
    "print(f\"  Model will be saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd680c2a",
   "metadata": {},
   "source": [
    "## Cell 2: Data Preparation with Class Weight Analysis\n",
    "\n",
    "This section loads the preprocessed_Public dataset and automatically calculates class weights to handle imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298e7cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes detected: ['test', 'train', 'val']\n",
      "\n",
      "Dataset Split:\n",
      "  Training: 6654 images\n",
      "  Validation: 1664 images\n",
      "\n",
      "Calculating class weights for imbalanced dataset...\n",
      "Class distribution in training set:\n",
      "  test: 322 samples\n",
      "  train: 6009 samples\n",
      "  val: 323 samples\n",
      "\n",
      "Class weights (normalized):\n",
      "  test: 6.8882\n",
      "  train: 0.3691\n",
      "  val: 6.8669\n"
     ]
    }
   ],
   "source": [
    "# Training transforms: Resize + Augmentation (Flip, Rotate, Color Jitter)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1), # Adds robustness to lighting\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation transforms: Resize only\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "try:\n",
    "    # Load dataset twice: once for train (with augmentation), once for val (clean)\n",
    "    full_data_train = datasets.ImageFolder(DATA_DIR, transform=train_transform)\n",
    "    full_data_val = datasets.ImageFolder(DATA_DIR, transform=val_transform)\n",
    "\n",
    "    # Get class names\n",
    "    class_names = full_data_train.classes\n",
    "    print(f\"Classes detected: {class_names}\")\n",
    "\n",
    "    # Create indices for split (80% Train, 20% Val)\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        list(range(len(full_data_train))),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=full_data_train.targets  # Ensure balanced split\n",
    "    )\n",
    "\n",
    "    # Create subsets\n",
    "    train_dataset = Subset(full_data_train, train_idx)\n",
    "    val_dataset = Subset(full_data_val, val_idx)\n",
    "\n",
    "    # Data Loaders\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2),\n",
    "        'val': DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    }\n",
    "    dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "    \n",
    "    print(f\"\\nDataset Split:\")\n",
    "    print(f\"  Training: {dataset_sizes['train']} images\")\n",
    "    print(f\"  Validation: {dataset_sizes['val']} images\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\nERROR: Could not find dataset!\")\n",
    "    print(f\"Make sure you have a folder named '{DATA_DIR}' with subfolders for each class.\")\n",
    "    print(f\"Error details: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# ==========================================\n",
    "# CALCULATE CLASS WEIGHTS (Handle Imbalanced Data)\n",
    "# ==========================================\n",
    "print(\"\\nCalculating class weights for imbalanced dataset...\")\n",
    "\n",
    "# Count samples per class in training set\n",
    "class_counts = np.zeros(NUM_CLASSES)\n",
    "for idx in train_idx:\n",
    "    label = full_data_train.targets[idx]\n",
    "    class_counts[label] += 1\n",
    "\n",
    "print(f\"Class distribution in training set:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"  {class_name}: {int(class_counts[i])} samples\")\n",
    "\n",
    "# Calculate weights inversely proportional to class frequency\n",
    "# Gives more weight to underrepresented classes\n",
    "total_samples = np.sum(class_counts)\n",
    "class_weights = total_samples / (NUM_CLASSES * class_counts)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "print(f\"\\nClass weights (normalized):\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"  {class_name}: {class_weights[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b5d40d",
   "metadata": {},
   "source": [
    "## Cell 3: Model Setup (ResNet50 + Dropout)\n",
    "\n",
    "Initialize ResNet50 with pretrained ImageNet weights and add a custom classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1812d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing ResNet50...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInitializing ResNet50...\")\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Modify the final layer (The Classifier)\n",
    "# ResNet50's default input to the final layer is 2048 features\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),            # Strong dropout to prevent overfitting\n",
    "    nn.Linear(num_ftrs, 512),   # Add an intermediate layer\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),            # Mild dropout\n",
    "    nn.Linear(512, NUM_CLASSES) # Final output (3 classes)\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c2ee8",
   "metadata": {},
   "source": [
    "## Cell 4: Training Setup with Early Stopping & Class Weights\n",
    "\n",
    "Configure the loss function with class weights, optimizer, scheduler, and early stopping mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a90b85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STARTING TRAINING\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Epoch 1/15\n",
      "======================================================================\n",
      "  TRAIN | Batch 1/832 | Loss: 1.0864 | Acc: 0.1250\n",
      "  TRAIN | Batch 5/832 | Loss: 1.0684 | Acc: 0.5750\n",
      "  TRAIN | Batch 10/832 | Loss: 1.0920 | Acc: 0.6750\n",
      "  TRAIN | Batch 15/832 | Loss: 1.0416 | Acc: 0.7667\n",
      "  TRAIN | Batch 20/832 | Loss: 1.0369 | Acc: 0.7812\n",
      "  TRAIN | Batch 25/832 | Loss: 1.0019 | Acc: 0.8050\n",
      "  TRAIN | Batch 30/832 | Loss: 0.9994 | Acc: 0.8250\n",
      "  TRAIN | Batch 35/832 | Loss: 0.9853 | Acc: 0.8393\n",
      "  TRAIN | Batch 40/832 | Loss: 0.9633 | Acc: 0.8469\n",
      "  TRAIN | Batch 45/832 | Loss: 0.9724 | Acc: 0.8528\n",
      "  TRAIN | Batch 50/832 | Loss: 0.9708 | Acc: 0.8600\n",
      "  TRAIN | Batch 55/832 | Loss: 1.0056 | Acc: 0.8568\n",
      "  TRAIN | Batch 60/832 | Loss: 1.0037 | Acc: 0.8646\n",
      "  TRAIN | Batch 65/832 | Loss: 1.0089 | Acc: 0.8577\n",
      "  TRAIN | Batch 70/832 | Loss: 1.0188 | Acc: 0.8554\n",
      "  TRAIN | Batch 75/832 | Loss: 1.0017 | Acc: 0.8617\n",
      "  TRAIN | Batch 80/832 | Loss: 1.0176 | Acc: 0.8562\n",
      "  TRAIN | Batch 85/832 | Loss: 1.0207 | Acc: 0.8559\n",
      "  TRAIN | Batch 90/832 | Loss: 1.0314 | Acc: 0.8500\n",
      "  TRAIN | Batch 95/832 | Loss: 1.0206 | Acc: 0.8539\n",
      "  TRAIN | Batch 100/832 | Loss: 1.0158 | Acc: 0.8538\n",
      "  TRAIN | Batch 105/832 | Loss: 1.0095 | Acc: 0.8548\n",
      "  TRAIN | Batch 110/832 | Loss: 0.9964 | Acc: 0.8580\n",
      "  TRAIN | Batch 115/832 | Loss: 0.9904 | Acc: 0.8609\n",
      "  TRAIN | Batch 120/832 | Loss: 0.9724 | Acc: 0.8667\n",
      "  TRAIN | Batch 125/832 | Loss: 0.9991 | Acc: 0.8710\n",
      "  TRAIN | Batch 130/832 | Loss: 0.9941 | Acc: 0.8721\n",
      "  TRAIN | Batch 135/832 | Loss: 0.9824 | Acc: 0.8759\n",
      "  TRAIN | Batch 140/832 | Loss: 0.9888 | Acc: 0.8768\n",
      "  TRAIN | Batch 145/832 | Loss: 0.9915 | Acc: 0.8759\n",
      "  TRAIN | Batch 150/832 | Loss: 0.9845 | Acc: 0.8783\n",
      "  TRAIN | Batch 155/832 | Loss: 0.9767 | Acc: 0.8806\n",
      "  TRAIN | Batch 160/832 | Loss: 0.9710 | Acc: 0.8828\n",
      "  TRAIN | Batch 165/832 | Loss: 0.9692 | Acc: 0.8833\n",
      "  TRAIN | Batch 170/832 | Loss: 0.9817 | Acc: 0.8816\n",
      "  TRAIN | Batch 175/832 | Loss: 0.9783 | Acc: 0.8829\n",
      "  TRAIN | Batch 180/832 | Loss: 0.9807 | Acc: 0.8819\n",
      "  TRAIN | Batch 185/832 | Loss: 0.9720 | Acc: 0.8845\n",
      "  TRAIN | Batch 190/832 | Loss: 0.9721 | Acc: 0.8842\n",
      "  TRAIN | Batch 195/832 | Loss: 0.9735 | Acc: 0.8827\n",
      "  TRAIN | Batch 200/832 | Loss: 0.9745 | Acc: 0.8812\n",
      "  TRAIN | Batch 205/832 | Loss: 0.9689 | Acc: 0.8817\n",
      "  TRAIN | Batch 210/832 | Loss: 0.9653 | Acc: 0.8821\n",
      "  TRAIN | Batch 215/832 | Loss: 0.9627 | Acc: 0.8820\n",
      "  TRAIN | Batch 220/832 | Loss: 0.9620 | Acc: 0.8818\n",
      "  TRAIN | Batch 225/832 | Loss: 0.9609 | Acc: 0.8828\n",
      "  TRAIN | Batch 230/832 | Loss: 0.9612 | Acc: 0.8815\n",
      "  TRAIN | Batch 235/832 | Loss: 0.9623 | Acc: 0.8798\n",
      "  TRAIN | Batch 240/832 | Loss: 0.9578 | Acc: 0.8807\n",
      "  TRAIN | Batch 245/832 | Loss: 0.9567 | Acc: 0.8806\n",
      "  TRAIN | Batch 250/832 | Loss: 0.9516 | Acc: 0.8800\n",
      "  TRAIN | Batch 255/832 | Loss: 0.9463 | Acc: 0.8804\n",
      "  TRAIN | Batch 260/832 | Loss: 0.9471 | Acc: 0.8803\n",
      "  TRAIN | Batch 265/832 | Loss: 0.9425 | Acc: 0.8807\n",
      "  TRAIN | Batch 270/832 | Loss: 0.9479 | Acc: 0.8796\n",
      "  TRAIN | Batch 275/832 | Loss: 0.9422 | Acc: 0.8809\n",
      "  TRAIN | Batch 280/832 | Loss: 0.9407 | Acc: 0.8812\n",
      "  TRAIN | Batch 285/832 | Loss: 0.9401 | Acc: 0.8807\n",
      "  TRAIN | Batch 290/832 | Loss: 0.9341 | Acc: 0.8815\n",
      "  TRAIN | Batch 295/832 | Loss: 0.9310 | Acc: 0.8818\n",
      "  TRAIN | Batch 300/832 | Loss: 0.9313 | Acc: 0.8812\n",
      "  TRAIN | Batch 305/832 | Loss: 0.9356 | Acc: 0.8807\n",
      "  TRAIN | Batch 310/832 | Loss: 0.9367 | Acc: 0.8802\n",
      "  TRAIN | Batch 315/832 | Loss: 0.9374 | Acc: 0.8798\n",
      "  TRAIN | Batch 320/832 | Loss: 0.9361 | Acc: 0.8789\n",
      "  TRAIN | Batch 325/832 | Loss: 0.9329 | Acc: 0.8796\n",
      "  TRAIN | Batch 330/832 | Loss: 0.9300 | Acc: 0.8780\n",
      "  TRAIN | Batch 335/832 | Loss: 0.9283 | Acc: 0.8780\n",
      "  TRAIN | Batch 340/832 | Loss: 0.9274 | Acc: 0.8765\n",
      "  TRAIN | Batch 345/832 | Loss: 0.9223 | Acc: 0.8757\n",
      "  TRAIN | Batch 350/832 | Loss: 0.9224 | Acc: 0.8757\n",
      "  TRAIN | Batch 355/832 | Loss: 0.9235 | Acc: 0.8750\n",
      "  TRAIN | Batch 360/832 | Loss: 0.9194 | Acc: 0.8750\n",
      "  TRAIN | Batch 365/832 | Loss: 0.9260 | Acc: 0.8740\n",
      "  TRAIN | Batch 370/832 | Loss: 0.9217 | Acc: 0.8750\n",
      "  TRAIN | Batch 375/832 | Loss: 0.9205 | Acc: 0.8757\n",
      "  TRAIN | Batch 380/832 | Loss: 0.9157 | Acc: 0.8770\n",
      "  TRAIN | Batch 385/832 | Loss: 0.9130 | Acc: 0.8773\n",
      "  TRAIN | Batch 390/832 | Loss: 0.9219 | Acc: 0.8769\n",
      "  TRAIN | Batch 395/832 | Loss: 0.9229 | Acc: 0.8769\n",
      "  TRAIN | Batch 400/832 | Loss: 0.9228 | Acc: 0.8772\n",
      "  TRAIN | Batch 405/832 | Loss: 0.9191 | Acc: 0.8784\n",
      "  TRAIN | Batch 410/832 | Loss: 0.9184 | Acc: 0.8784\n",
      "  TRAIN | Batch 415/832 | Loss: 0.9161 | Acc: 0.8792\n",
      "  TRAIN | Batch 420/832 | Loss: 0.9174 | Acc: 0.8789\n",
      "  TRAIN | Batch 425/832 | Loss: 0.9157 | Acc: 0.8791\n",
      "  TRAIN | Batch 430/832 | Loss: 0.9133 | Acc: 0.8799\n",
      "  TRAIN | Batch 435/832 | Loss: 0.9088 | Acc: 0.8805\n",
      "  TRAIN | Batch 440/832 | Loss: 0.9074 | Acc: 0.8810\n",
      "  TRAIN | Batch 445/832 | Loss: 0.9050 | Acc: 0.8817\n",
      "  TRAIN | Batch 450/832 | Loss: 0.9030 | Acc: 0.8819\n",
      "  TRAIN | Batch 455/832 | Loss: 0.9004 | Acc: 0.8821\n",
      "  TRAIN | Batch 460/832 | Loss: 0.8997 | Acc: 0.8826\n",
      "  TRAIN | Batch 465/832 | Loss: 0.8996 | Acc: 0.8825\n",
      "  TRAIN | Batch 470/832 | Loss: 0.9000 | Acc: 0.8822\n",
      "  TRAIN | Batch 475/832 | Loss: 0.8995 | Acc: 0.8824\n",
      "  TRAIN | Batch 480/832 | Loss: 0.8998 | Acc: 0.8820\n",
      "  TRAIN | Batch 485/832 | Loss: 0.8972 | Acc: 0.8830\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 193\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m trained_model, training_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 106\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, early_stopping, num_epochs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Track history if only in train\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 106\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    108\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m--> 276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:253\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:146\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    144\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m--> 146\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m    148\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:553\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    537\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    538\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    546\u001b[0m     )\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# LOSS FUNCTION WITH CLASS WEIGHTS\n",
    "# ==========================================\n",
    "# CrossEntropyLoss with class weights to handle imbalanced data\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Adam optimizer is generally faster at converging than SGD\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Scheduler: if validation accuracy doesn't improve, lower the learning rate\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n",
    "\n",
    "# ==========================================\n",
    "# EARLY STOPPING CLASS\n",
    "# ==========================================\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Stops training when validation metric stops improving.\n",
    "    Saves the best model weights.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0.001, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_wts = None\n",
    "        \n",
    "    def __call__(self, val_acc, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_acc\n",
    "            self.best_model_wts = model.state_dict().copy()\n",
    "        elif val_acc > self.best_score + self.min_delta:\n",
    "            self.best_score = val_acc\n",
    "            self.counter = 0\n",
    "            self.best_model_wts = model.state_dict().copy()\n",
    "            if self.verbose:\n",
    "                print(f\"    ✓ Validation improved! New best accuracy: {val_acc:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"    ✗ No improvement. Patience: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(f\"    ⚠ EARLY STOPPING TRIGGERED after {self.patience} epochs without improvement!\")\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(patience=PATIENCE, min_delta=MIN_DELTA, verbose=True)\n",
    "\n",
    "# ==========================================\n",
    "# TRAINING LOOP WITH METRICS TRACKING\n",
    "# ==========================================\n",
    "def train_model(model, criterion, optimizer, scheduler, early_stopping, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping and comprehensive metrics tracking.\n",
    "    \n",
    "    Tracks:\n",
    "    - Loss & Accuracy\n",
    "    - Precision, Recall, F1 Score\n",
    "    - Best model checkpoint\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'train_precision': [], 'val_precision': [],\n",
    "        'train_recall': [], 'val_recall': [],\n",
    "        'train_f1': [], 'val_f1': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\n{\"=\"*70}')\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'{\"=\"*70}')\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            # Store predictions and labels for metrics calculation\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            # Iterate over data\n",
    "            for batch_idx, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                batch_count += 1\n",
    "                \n",
    "                # Store predictions and labels for metrics\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Print batch progress every 5 batches\n",
    "                if (batch_idx + 1) % 5 == 0 or batch_idx == 0:\n",
    "                    current_loss = running_loss / (batch_count * BATCH_SIZE)\n",
    "                    current_acc = running_corrects.double() / (batch_count * BATCH_SIZE)\n",
    "                    num_batches = len(dataloaders[phase])\n",
    "                    print(f'  {phase.upper()} | Batch {batch_idx+1}/{num_batches} | Loss: {current_loss:.4f} | Acc: {current_acc:.4f}')\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            # Calculate additional metrics\n",
    "            all_preds = np.array(all_preds)\n",
    "            all_labels = np.array(all_labels)\n",
    "            \n",
    "            epoch_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "            epoch_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "            epoch_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "            # Get current learning rate\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            print(f'\\n  {phase.upper()} SUMMARY')\n",
    "            print(f'    Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')\n",
    "            print(f'    Precision: {epoch_precision:.4f} | Recall: {epoch_recall:.4f} | F1: {epoch_f1:.4f}')\n",
    "            print(f'    Learning Rate: {current_lr:.2e}')\n",
    "            \n",
    "            # Store metrics in history\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())\n",
    "            history[f'{phase}_precision'].append(epoch_precision)\n",
    "            history[f'{phase}_recall'].append(epoch_recall)\n",
    "            history[f'{phase}_f1'].append(epoch_f1)\n",
    "\n",
    "            # Deep copy the model if it's the best one so far\n",
    "            if phase == 'val':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    print(f'  *** NEW BEST MODEL! Validation Accuracy: {epoch_acc:.4f} ***')\n",
    "                \n",
    "                # Check early stopping and step scheduler\n",
    "                early_stopping(epoch_acc.item(), model)\n",
    "                scheduler.step(epoch_acc)\n",
    "                \n",
    "                if early_stopping.early_stop:\n",
    "                    print(f\"\\nTraining stopped early at epoch {epoch+1}/{num_epochs}\")\n",
    "                    break\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\n{\"=\"*70}')\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    print(f'{\"=\"*70}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(early_stopping.best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "# ==========================================\n",
    "# RUN TRAINING & SAVE MODEL\n",
    "# ==========================================\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Train\n",
    "    trained_model, training_history = train_model(model, criterion, optimizer, scheduler, early_stopping, NUM_EPOCHS)\n",
    "    \n",
    "    # Save the trained model\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SAVING MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Save model state dict (recommended approach)\n",
    "    torch.save({\n",
    "        'model_state_dict': trained_model.state_dict(),\n",
    "        'class_names': class_names,\n",
    "        'training_history': training_history,\n",
    "        'model_config': {\n",
    "            'num_classes': NUM_CLASSES,\n",
    "            'architecture': 'ResNet50'\n",
    "        }\n",
    "    }, MODEL_SAVE_PATH)\n",
    "    \n",
    "    print(f\"✓ Model successfully saved to: {MODEL_SAVE_PATH}\")\n",
    "    print(f\"  File size: {os.path.getsize(MODEL_SAVE_PATH) / (1024*1024):.2f} MB\")\n",
    "    print(f\"\\nModel includes:\")\n",
    "    print(f\"  - Trained weights (state_dict)\")\n",
    "    print(f\"  - Class names: {class_names}\")\n",
    "    print(f\"  - Training history (loss, accuracy, metrics)\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952e70c",
   "metadata": {},
   "source": [
    "## Cell 5: Training History Visualization\n",
    "\n",
    "Visualize the training and validation metrics over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2270978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(training_history['train_loss'], label='Train', marker='o')\n",
    "axes[0, 0].plot(training_history['val_loss'], label='Val', marker='s')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training & Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0, 1].plot(training_history['train_acc'], label='Train', marker='o')\n",
    "axes[0, 1].plot(training_history['val_acc'], label='Val', marker='s')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].set_title('Training & Validation Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision, Recall, F1 plot\n",
    "axes[1, 0].plot(training_history['train_precision'], label='Train Precision', marker='o')\n",
    "axes[1, 0].plot(training_history['val_precision'], label='Val Precision', marker='s')\n",
    "axes[1, 0].plot(training_history['train_recall'], label='Train Recall', marker='^')\n",
    "axes[1, 0].plot(training_history['val_recall'], label='Val Recall', marker='d')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Score')\n",
    "axes[1, 0].set_title('Precision & Recall')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score plot\n",
    "axes[1, 1].plot(training_history['train_f1'], label='Train', marker='o')\n",
    "axes[1, 1].plot(training_history['val_f1'], label='Val', marker='s')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('F1 Score')\n",
    "axes[1, 1].set_title('F1 Score (Weighted Average)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f7872",
   "metadata": {},
   "source": [
    "## Cell 6: Model Evaluation on Test Set 1 (preprocessed_self)\n",
    "\n",
    "This cell evaluates the trained model on the first test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# EVALUATION ON TEST SET 1: preprocessed_self\n",
    "# This cell can run independently after training\n",
    "# ==========================================\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "def load_trained_model(model_path, device):\n",
    "    \"\"\"Load the trained model from checkpoint.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file {model_path} not found! Please train the model first.\")\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Recreate model architecture\n",
    "    model = models.resnet50(weights=None)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    num_classes = checkpoint['model_config']['num_classes']\n",
    "    \n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_ftrs, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    # Load trained weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, checkpoint['class_names']\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"Evaluate the model and return predictions and labels.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix', save_path=None):\n",
    "    \"\"\"Plot confusion matrix using seaborn heatmap.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"  ✓ Confusion matrix saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# LOAD MODEL & EVALUATE ON TEST SET 1\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATING ON TEST SET 1: preprocessed_self\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Validation transform (no augmentation for testing)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the trained model\n",
    "try:\n",
    "    model, class_names = load_trained_model(MODEL_SAVE_PATH, DEVICE)\n",
    "    print(f\"✓ Model loaded from: {MODEL_SAVE_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading model: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Load test dataset 1\n",
    "try:\n",
    "    test_dataset_1 = datasets.ImageFolder(TEST_DIR_1, transform=test_transform)\n",
    "    test_loader_1 = DataLoader(test_dataset_1, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    print(f\"✓ Test dataset loaded from: {TEST_DIR_1}\")\n",
    "    print(f\"  Classes: {test_dataset_1.classes}\")\n",
    "    print(f\"  Total images: {len(test_dataset_1)}\")\n",
    "    \n",
    "    # Class distribution\n",
    "    test_labels_1 = [label for _, label in test_dataset_1.samples]\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        count = test_labels_1.count(i)\n",
    "        print(f\"    - {class_name}: {count} images\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading test dataset: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Evaluate on test set 1\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Running inference...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "preds_1, labels_1, probs_1 = evaluate_model(model, test_loader_1, DEVICE)\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df_1 = pd.DataFrame({\n",
    "    'Image_Index': range(len(labels_1)),\n",
    "    'True_Label': [class_names[label] for label in labels_1],\n",
    "    'Predicted_Label': [class_names[pred] for pred in preds_1],\n",
    "    'Confidence': [probs_1[i][preds_1[i]] for i in range(len(preds_1))]\n",
    "})\n",
    "\n",
    "# Add probability columns for each class\n",
    "for i, class_name in enumerate(class_names):\n",
    "    predictions_df_1[f'Prob_{class_name}'] = probs_1[:, i]\n",
    "\n",
    "csv_path_1 = 'predictions_preprocessed_self.csv'\n",
    "predictions_df_1.to_csv(csv_path_1, index=False)\n",
    "print(f\"\\n✓ Predictions saved to: {csv_path_1}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm_1 = confusion_matrix(labels_1, preds_1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT - TEST SET 1 (preprocessed_self)\")\n",
    "print(\"=\"*70)\n",
    "report_1 = classification_report(labels_1, preds_1, target_names=class_names, digits=4)\n",
    "print(report_1)\n",
    "\n",
    "# Save classification report\n",
    "with open('classification_report_preprocessed_self.txt', 'w') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"CLASSIFICATION REPORT - TEST SET 1 (preprocessed_self)\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(report_1)\n",
    "print(\"✓ Classification report saved to: classification_report_preprocessed_self.txt\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFUSION MATRIX - TEST SET 1\")\n",
    "print(\"=\"*70)\n",
    "plot_confusion_matrix(cm_1, class_names, \n",
    "                     title='Confusion Matrix - preprocessed_self Dataset',\n",
    "                     save_path='confusion_matrix_preprocessed_self.png')\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-CLASS METRICS - TEST SET 1\")\n",
    "print(\"=\"*70)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_accuracy = cm_1[i, i] / cm_1[i, :].sum() if cm_1[i, :].sum() > 0 else 0\n",
    "    print(f\"  {class_name}:\")\n",
    "    print(f\"    Accuracy: {class_accuracy:.4f} ({cm_1[i, i]}/{cm_1[i, :].sum()})\")\n",
    "\n",
    "# Overall metrics\n",
    "overall_accuracy_1 = np.trace(cm_1) / np.sum(cm_1)\n",
    "precision_1, recall_1, f1_1, _ = precision_recall_fscore_support(labels_1, preds_1, average='weighted')\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"OVERALL METRICS - TEST SET 1 (preprocessed_self)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  Overall Accuracy: {overall_accuracy_1:.4f}\")\n",
    "print(f\"  Weighted Precision: {precision_1:.4f}\")\n",
    "print(f\"  Weighted Recall: {recall_1:.4f}\")\n",
    "print(f\"  Weighted F1-Score: {f1_1:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save summary metrics\n",
    "metrics_summary_1 = {\n",
    "    'Dataset': 'preprocessed_self',\n",
    "    'Total_Samples': len(labels_1),\n",
    "    'Overall_Accuracy': overall_accuracy_1,\n",
    "    'Weighted_Precision': precision_1,\n",
    "    'Weighted_Recall': recall_1,\n",
    "    'Weighted_F1': f1_1\n",
    "}\n",
    "\n",
    "metrics_df_1 = pd.DataFrame([metrics_summary_1])\n",
    "metrics_df_1.to_csv('metrics_summary_preprocessed_self.csv', index=False)\n",
    "print(f\"\\n✓ Metrics summary saved to: metrics_summary_preprocessed_self.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db7e46",
   "metadata": {},
   "source": [
    "## Cell 7: Model Evaluation on Test Set 2 (SelfCollected_Dataset)\n",
    "\n",
    "This cell evaluates the trained model on the second test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c4499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# EVALUATION ON TEST SET 2: SelfCollected_Dataset\n",
    "# This cell can run independently after training\n",
    "# ==========================================\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATING ON TEST SET 2: SelfCollected_Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Test transform\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the trained model (reuse functions from previous cell)\n",
    "try:\n",
    "    model, class_names = load_trained_model(MODEL_SAVE_PATH, DEVICE)\n",
    "    print(f\"✓ Model loaded from: {MODEL_SAVE_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading model: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Load test dataset 2\n",
    "try:\n",
    "    test_dataset_2 = datasets.ImageFolder(TEST_DIR_2, transform=test_transform)\n",
    "    test_loader_2 = DataLoader(test_dataset_2, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    print(f\"✓ Test dataset loaded from: {TEST_DIR_2}\")\n",
    "    print(f\"  Classes: {test_dataset_2.classes}\")\n",
    "    print(f\"  Total images: {len(test_dataset_2)}\")\n",
    "    \n",
    "    # Class distribution\n",
    "    test_labels_2 = [label for _, label in test_dataset_2.samples]\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        count = test_labels_2.count(i)\n",
    "        print(f\"    - {class_name}: {count} images\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading test dataset: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Evaluate on test set 2\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Running inference...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "preds_2, labels_2, probs_2 = evaluate_model(model, test_loader_2, DEVICE)\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df_2 = pd.DataFrame({\n",
    "    'Image_Index': range(len(labels_2)),\n",
    "    'True_Label': [class_names[label] for label in labels_2],\n",
    "    'Predicted_Label': [class_names[pred] for pred in preds_2],\n",
    "    'Confidence': [probs_2[i][preds_2[i]] for i in range(len(preds_2))]\n",
    "})\n",
    "\n",
    "# Add probability columns for each class\n",
    "for i, class_name in enumerate(class_names):\n",
    "    predictions_df_2[f'Prob_{class_name}'] = probs_2[:, i]\n",
    "\n",
    "csv_path_2 = 'predictions_SelfCollected_Dataset.csv'\n",
    "predictions_df_2.to_csv(csv_path_2, index=False)\n",
    "print(f\"\\n✓ Predictions saved to: {csv_path_2}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm_2 = confusion_matrix(labels_2, preds_2)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT - TEST SET 2 (SelfCollected_Dataset)\")\n",
    "print(\"=\"*70)\n",
    "report_2 = classification_report(labels_2, preds_2, target_names=class_names, digits=4)\n",
    "print(report_2)\n",
    "\n",
    "# Save classification report\n",
    "with open('classification_report_SelfCollected_Dataset.txt', 'w') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"CLASSIFICATION REPORT - TEST SET 2 (SelfCollected_Dataset)\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(report_2)\n",
    "print(\"✓ Classification report saved to: classification_report_SelfCollected_Dataset.txt\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFUSION MATRIX - TEST SET 2\")\n",
    "print(\"=\"*70)\n",
    "plot_confusion_matrix(cm_2, class_names, \n",
    "                     title='Confusion Matrix - SelfCollected_Dataset',\n",
    "                     save_path='confusion_matrix_SelfCollected_Dataset.png')\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-CLASS METRICS - TEST SET 2\")\n",
    "print(\"=\"*70)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_accuracy = cm_2[i, i] / cm_2[i, :].sum() if cm_2[i, :].sum() > 0 else 0\n",
    "    print(f\"  {class_name}:\")\n",
    "    print(f\"    Accuracy: {class_accuracy:.4f} ({cm_2[i, i]}/{cm_2[i, :].sum()})\")\n",
    "\n",
    "# Overall metrics\n",
    "overall_accuracy_2 = np.trace(cm_2) / np.sum(cm_2)\n",
    "precision_2, recall_2, f1_2, _ = precision_recall_fscore_support(labels_2, preds_2, average='weighted')\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"OVERALL METRICS - TEST SET 2 (SelfCollected_Dataset)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  Overall Accuracy: {overall_accuracy_2:.4f}\")\n",
    "print(f\"  Weighted Precision: {precision_2:.4f}\")\n",
    "print(f\"  Weighted Recall: {recall_2:.4f}\")\n",
    "print(f\"  Weighted F1-Score: {f1_2:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save summary metrics\n",
    "metrics_summary_2 = {\n",
    "    'Dataset': 'SelfCollected_Dataset',\n",
    "    'Total_Samples': len(labels_2),\n",
    "    'Overall_Accuracy': overall_accuracy_2,\n",
    "    'Weighted_Precision': precision_2,\n",
    "    'Weighted_Recall': recall_2,\n",
    "    'Weighted_F1': f1_2\n",
    "}\n",
    "\n",
    "metrics_df_2 = pd.DataFrame([metrics_summary_2])\n",
    "metrics_df_2.to_csv('metrics_summary_SelfCollected_Dataset.csv', index=False)\n",
    "print(f\"\\n✓ Metrics summary saved to: metrics_summary_SelfCollected_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2ece1",
   "metadata": {},
   "source": [
    "## Cell 8: Comparative Analysis of Both Test Sets\n",
    "\n",
    "This cell compares the performance on both test datasets side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d91d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# COMPARATIVE ANALYSIS OF BOTH TEST SETS\n",
    "# ==========================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARATIVE ANALYSIS: preprocessed_self vs SelfCollected_Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Combine metrics from both test sets\n",
    "comparison_data = {\n",
    "    'Metric': ['Overall Accuracy', 'Weighted Precision', 'Weighted Recall', 'Weighted F1-Score'],\n",
    "    'preprocessed_self': [overall_accuracy_1, precision_1, recall_1, f1_1],\n",
    "    'SelfCollected_Dataset': [overall_accuracy_2, precision_2, recall_2, f1_2]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('test_sets_comparison.csv', index=False)\n",
    "print(f\"\\n✓ Comparison saved to: test_sets_comparison.csv\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart comparison\n",
    "metrics = comparison_df['Metric']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, comparison_df['preprocessed_self'], width, label='preprocessed_self', alpha=0.8)\n",
    "axes[0].bar(x + width/2, comparison_df['SelfCollected_Dataset'], width, label='SelfCollected_Dataset', alpha=0.8)\n",
    "axes[0].set_xlabel('Metrics', fontsize=12)\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "axes[0].set_title('Performance Comparison: Two Test Datasets', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics, rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_ylim([0, 1.0])\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[0].text(i - width/2, comparison_df['preprocessed_self'][i] + 0.02, \n",
    "                f'{comparison_df[\"preprocessed_self\"][i]:.3f}', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    axes[0].text(i + width/2, comparison_df['SelfCollected_Dataset'][i] + 0.02, \n",
    "                f'{comparison_df[\"SelfCollected_Dataset\"][i]:.3f}', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Per-class accuracy comparison\n",
    "class_acc_1 = [cm_1[i, i] / cm_1[i, :].sum() if cm_1[i, :].sum() > 0 else 0 \n",
    "               for i in range(len(class_names))]\n",
    "class_acc_2 = [cm_2[i, i] / cm_2[i, :].sum() if cm_2[i, :].sum() > 0 else 0 \n",
    "               for i in range(len(class_names))]\n",
    "\n",
    "x_classes = np.arange(len(class_names))\n",
    "axes[1].bar(x_classes - width/2, class_acc_1, width, label='preprocessed_self', alpha=0.8)\n",
    "axes[1].bar(x_classes + width/2, class_acc_2, width, label='SelfCollected_Dataset', alpha=0.8)\n",
    "axes[1].set_xlabel('Class', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Per-Class Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x_classes)\n",
    "axes[1].set_xticklabels(class_names)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_ylim([0, 1.0])\n",
    "\n",
    "# Add value labels\n",
    "for i, class_name in enumerate(class_names):\n",
    "    axes[1].text(i - width/2, class_acc_1[i] + 0.02, f'{class_acc_1[i]:.3f}', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    axes[1].text(i + width/2, class_acc_2[i] + 0.02, f'{class_acc_2[i]:.3f}', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_sets_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Comparison chart saved to: test_sets_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-CLASS ACCURACY COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    print(f\"  preprocessed_self:       {class_acc_1[i]:.4f}\")\n",
    "    print(f\"  SelfCollected_Dataset:   {class_acc_2[i]:.4f}\")\n",
    "    diff = class_acc_2[i] - class_acc_1[i]\n",
    "    print(f\"  Difference:              {diff:+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTest Set 1 (preprocessed_self):\")\n",
    "print(f\"  Samples: {len(labels_1)}\")\n",
    "print(f\"  Overall Accuracy: {overall_accuracy_1:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set 2 (SelfCollected_Dataset):\")\n",
    "print(f\"  Samples: {len(labels_2)}\")\n",
    "print(f\"  Overall Accuracy: {overall_accuracy_2:.4f}\")\n",
    "\n",
    "print(f\"\\nAccuracy Difference: {(overall_accuracy_2 - overall_accuracy_1):+.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create comprehensive summary file\n",
    "with open('comprehensive_evaluation_summary.txt', 'w') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"COMPREHENSIVE EVALUATION SUMMARY\\n\")\n",
    "    f.write(\"ResNet50 Waste Classification Model\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"TRAINING CONFIGURATION:\\n\")\n",
    "    f.write(f\"  Training Dataset: {DATA_DIR}\\n\")\n",
    "    f.write(f\"  Model: ResNet50 (Fine-tuned)\\n\")\n",
    "    f.write(f\"  Classes: {class_names}\\n\")\n",
    "    f.write(f\"  Epochs: {NUM_EPOCHS}\\n\")\n",
    "    f.write(f\"  Batch Size: {BATCH_SIZE}\\n\")\n",
    "    f.write(f\"  Learning Rate: {LEARNING_RATE}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"TEST SET 1: preprocessed_self\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"Total Samples: {len(labels_1)}\\n\")\n",
    "    f.write(f\"Overall Accuracy: {overall_accuracy_1:.4f}\\n\")\n",
    "    f.write(f\"Weighted Precision: {precision_1:.4f}\\n\")\n",
    "    f.write(f\"Weighted Recall: {recall_1:.4f}\\n\")\n",
    "    f.write(f\"Weighted F1-Score: {f1_1:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Per-Class Accuracy:\\n\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        f.write(f\"  {class_name}: {class_acc_1[i]:.4f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    f.write(\"TEST SET 2: SelfCollected_Dataset\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"Total Samples: {len(labels_2)}\\n\")\n",
    "    f.write(f\"Overall Accuracy: {overall_accuracy_2:.4f}\\n\")\n",
    "    f.write(f\"Weighted Precision: {precision_2:.4f}\\n\")\n",
    "    f.write(f\"Weighted Recall: {recall_2:.4f}\\n\")\n",
    "    f.write(f\"Weighted F1-Score: {f1_2:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Per-Class Accuracy:\\n\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        f.write(f\"  {class_name}: {class_acc_2[i]:.4f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    f.write(\"FILES GENERATED:\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"  - {MODEL_SAVE_PATH} (trained model)\\n\")\n",
    "    f.write(\"  - predictions_preprocessed_self.csv\\n\")\n",
    "    f.write(\"  - predictions_SelfCollected_Dataset.csv\\n\")\n",
    "    f.write(\"  - classification_report_preprocessed_self.txt\\n\")\n",
    "    f.write(\"  - classification_report_SelfCollected_Dataset.txt\\n\")\n",
    "    f.write(\"  - confusion_matrix_preprocessed_self.png\\n\")\n",
    "    f.write(\"  - confusion_matrix_SelfCollected_Dataset.png\\n\")\n",
    "    f.write(\"  - metrics_summary_preprocessed_self.csv\\n\")\n",
    "    f.write(\"  - metrics_summary_SelfCollected_Dataset.csv\\n\")\n",
    "    f.write(\"  - test_sets_comparison.csv\\n\")\n",
    "    f.write(\"  - test_sets_comparison.png\\n\")\n",
    "    f.write(\"  - comprehensive_evaluation_summary.txt\\n\")\n",
    "\n",
    "print(\"\\n✓ Comprehensive summary saved to: comprehensive_evaluation_summary.txt\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nAll results have been saved. Check the working directory for:\")\n",
    "print(\"  - Model checkpoint\")\n",
    "print(\"  - Predictions (CSV)\")\n",
    "print(\"  - Classification reports (TXT)\")\n",
    "print(\"  - Confusion matrices (PNG)\")\n",
    "print(\"  - Metrics summaries (CSV)\")\n",
    "print(\"  - Comparison charts (PNG)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

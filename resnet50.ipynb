{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aecbee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch with CUDA 12.1 installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch with GPU (CUDA) support\n",
    "# For CUDA 12.1 (most common). For other versions, see https://pytorch.org\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n",
    "print(\"PyTorch with CUDA 12.1 installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232f8470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Classes: ['aluminium', 'paper', 'plastic']\n",
      "Epoch 1/10 Train Loss 1.0237 Acc 0.4747 | Val Loss 0.9435 Acc 0.3333\n",
      "Epoch 2/10 Train Loss 0.8125 Acc 0.6707 | Val Loss 0.6497 Acc 0.9000\n",
      "Epoch 3/10 Train Loss 0.6955 Acc 0.7596 | Val Loss 0.5450 Acc 0.9333\n",
      "Epoch 4/10 Train Loss 0.6515 Acc 0.7879 | Val Loss 0.4791 Acc 0.9667\n",
      "Epoch 5/10 Train Loss 0.5745 Acc 0.7919 | Val Loss 0.4227 Acc 0.9667\n",
      "Epoch 6/10 Train Loss 0.5386 Acc 0.8121 | Val Loss 0.4414 Acc 0.8333\n",
      "Epoch 7/10 Train Loss 0.5319 Acc 0.7939 | Val Loss 0.4075 Acc 0.8333\n",
      "Epoch 8/10 Train Loss 0.4725 Acc 0.8566 | Val Loss 0.3485 Acc 0.9333\n",
      "Epoch 9/10 Train Loss 0.4536 Acc 0.8828 | Val Loss 0.3391 Acc 0.9667\n",
      "Epoch 10/10 Train Loss 0.4412 Acc 0.8545 | Val Loss 0.2859 Acc 0.9667\n",
      "Saved model: resnet50_waste.pth\n"
     ]
    }
   ],
   "source": [
    "# Ensure required packages are installed in the notebook environment\n",
    "# (This magic installs packages into the active Jupyter kernel)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# 1. Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Transforms\n",
    "IMG_SIZE = 512\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 3. Data\n",
    "# Assumes either Dataset/train & Dataset/val folders, or a single Dataset folder with class subfolders\n",
    "data_dir = 'Dataset'\n",
    "\n",
    "if os.path.isdir(os.path.join(data_dir, 'train')) and os.path.isdir(os.path.join(data_dir, 'val')):\n",
    "    image_datasets = {\n",
    "        'train': datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=data_transforms['train']),\n",
    "        'val': datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=data_transforms['val'])\n",
    "    }\n",
    "else:\n",
    "    full_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    # assign appropriate transforms\n",
    "    train_dataset.dataset.transform = data_transforms['train']\n",
    "    val_dataset.dataset.transform = data_transforms['val']\n",
    "    image_datasets = {'train': train_dataset, 'val': val_dataset}\n",
    "\n",
    "# get classes\n",
    "if hasattr(image_datasets['train'], 'classes'):\n",
    "    class_names = image_datasets['train'].classes\n",
    "else:\n",
    "    class_names = image_datasets['train'].dataset.classes\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# dataloaders\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=(x=='train'), num_workers=2)\n",
    "               for x in ['train', 'val']}\n",
    "\n",
    "# 4. Model\n",
    "# compatible with different torchvision versions\n",
    "try:\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "except Exception:\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "# 5. Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "# 6. Training and validation helpers\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total if total > 0 else 0.0\n",
    "    epoch_acc = correct / total if total > 0 else 0.0\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    epoch_loss = running_loss / total if total > 0 else 0.0\n",
    "    epoch_acc = correct / total if total > 0 else 0.0\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# 7. Run training\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model, dataloaders['train'], criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, dataloaders['val'], criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} Train Loss {train_loss:.4f} Acc {train_acc:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f}\")\n",
    "\n",
    "# 8. Save\n",
    "torch.save(model.state_dict(), 'resnet50_waste.pth')\n",
    "print(\"Saved model: resnet50_waste.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e7cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

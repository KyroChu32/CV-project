{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8da5923",
   "metadata": {},
   "source": [
    "# Vision Transformer (ViT-B16) - Waste Classification\n",
    "## PyTorch Implementation (Mac/MPS)\n",
    "\n",
    "**Model:** Vision Transformer Base 16 (ImageNet pretrained)\n",
    "\n",
    "**Objective:** Compare performance between preprocessed and raw datasets\n",
    "\n",
    "**Hardware:** MacBook Air M4 (MPS) / Windows RTX 3060 Ti (CUDA)\n",
    "\n",
    "**Classes:** aluminium, paper, plastic\n",
    "\n",
    "**Note:** ViT requires fixed input size of 224x224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd68bb",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1777235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import ViT_B_16_Weights\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# Import custom logger\n",
    "sys.path.append('..')\n",
    "from result_logger import log_result\n",
    "\n",
    "# Device configuration (auto-detect MPS/CUDA/CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU:\", torch.cuda.get_device_name(0))\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS (Apple Silicon)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29652b06",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Dataset Paths Configuration\n",
    "Define all dataset paths as constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e913d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Configuration\n",
    "CLASSES = ['aluminium', 'paper', 'plastic']\n",
    "NUM_CLASSES = 3\n",
    "IMG_SIZE = 224  # ViT requires 224x224 input\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4  # Adjust based on your system\n",
    "\n",
    "# Set A: Preprocessed Public (Training Data)\n",
    "PREPROCESSED_TRAIN = r\"../Dataset/preprocessed_Public/train\"\n",
    "PREPROCESSED_VAL = r\"../Dataset/preprocessed_Public/val\"\n",
    "PREPROCESSED_TEST_PUBLIC = r\"../Dataset/preprocessed_Public/test\"\n",
    "\n",
    "# Set B: Preprocessed Self-Collected (Final Testing)\n",
    "PREPROCESSED_TEST_SELF = r\"../Dataset/preprocessed_self/test\"\n",
    "\n",
    "# Set C: Raw Data (For Comparison)\n",
    "RAW_PUBLIC = r\"../Dataset/Public_dataset\"\n",
    "RAW_SELF = r\"../Dataset/SelfCollected_Dataset\"\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(\"✓ Paths configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca242c3",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Transforms Setup\n",
    "Define transformations with ImageNet normalization (critical for ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization statistics (required for ViT)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Training transforms with augmentation\n",
    "# Note: ViT is more sensitive to augmentation, so we use milder augmentations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),  # Milder rotation for ViT\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "print(\"✓ Data transforms defined\")\n",
    "print(f\"  Image size: {IMG_SIZE}x{IMG_SIZE} (ViT required size)\")\n",
    "print(f\"  Normalization: ImageNet (mean={IMAGENET_MEAN}, std={IMAGENET_STD})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d2e368",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. DataLoader Creation Function\n",
    "Create PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1703e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_path, val_path, test_path):\n",
    "    \"\"\"\n",
    "    Create PyTorch DataLoaders for training, validation, and testing\n",
    "    \n",
    "    Args:\n",
    "        train_path: Path to training data\n",
    "        val_path: Path to validation data\n",
    "        test_path: Path to test data\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, val_loader, test_loader\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load datasets using ImageFolder\n",
    "    train_dataset = datasets.ImageFolder(train_path, transform=train_transform)\n",
    "    val_dataset = datasets.ImageFolder(val_path, transform=val_test_transform)\n",
    "    test_dataset = datasets.ImageFolder(test_path, transform=val_test_transform)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset sizes:\")\n",
    "    print(f\"  Training:   {len(train_dataset)} images\")\n",
    "    print(f\"  Validation: {len(val_dataset)} images\")\n",
    "    print(f\"  Testing:    {len(test_dataset)} images\")\n",
    "    print(f\"  Classes: {train_dataset.classes}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "print(\"✓ DataLoader creation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9c49c",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Architecture\n",
    "Build Vision Transformer (ViT-B16) with custom classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13100994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vit_b16_model():\n",
    "    \"\"\"\n",
    "    Build Vision Transformer (ViT-B16) model with custom classification head\n",
    "    \n",
    "    Returns:\n",
    "        PyTorch model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pretrained ViT-B16\n",
    "    weights = ViT_B_16_Weights.DEFAULT\n",
    "    model = models.vit_b_16(weights=weights)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    # ViT has a 'heads' module with a single Linear layer\n",
    "    num_features = model.heads.head.in_features\n",
    "    \n",
    "    # Replace classifier with custom head\n",
    "    model.heads.head = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, NUM_CLASSES)\n",
    "    )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"✓ Model architecture function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0094d38",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Training Function\n",
    "Complete training pipeline with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd129a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, model_name, epochs=30):\n",
    "    \"\"\"\n",
    "    Train the PyTorch model\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        train_loader: Training DataLoader\n",
    "        val_loader: Validation DataLoader\n",
    "        model_name: Name for saving the model\n",
    "        epochs: Number of training epochs\n",
    "    \n",
    "    Returns:\n",
    "        Training history dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    # ViT benefits from AdamW with lower learning rate\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    patience_limit = 10\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Vision Transformer (ViT-B16)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n",
    "        for inputs, labels in train_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        epoch_train_loss = train_loss / train_total\n",
    "        epoch_train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]  ')\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                val_pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{100.*val_correct/val_total:.2f}%'\n",
    "                })\n",
    "        \n",
    "        epoch_val_loss = val_loss / val_total\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"  Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}\")\n",
    "        print(f\"  Val Loss:   {epoch_val_loss:.4f}, Val Acc:   {epoch_val_acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), f'models/{model_name}.pth')\n",
    "            print(f\"  ✓ Best model saved (Val Acc: {best_val_acc:.4f})\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience_limit:\n",
    "            print(f\"\\n  Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(f'models/{model_name}.pth'))\n",
    "    print(f\"\\n✓ Training completed. Best Val Acc: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"✓ Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d68b7f",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Evaluation Function\n",
    "Evaluate model and generate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac777c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, experiment_name):\n",
    "    \"\"\"\n",
    "    Evaluate model and display results\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        test_loader: Test DataLoader\n",
    "        experiment_name: Name of the experiment\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating: {experiment_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Testing'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = test_loss / test_total\n",
    "    test_acc = test_correct / test_total\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=CLASSES))\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "    plt.title(f'Confusion Matrix - {experiment_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Results Summary - {experiment_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Test Loss:      {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy:  {test_acc:.4f}\")\n",
    "    print(f\"Precision:      {precision:.4f}\")\n",
    "    print(f\"Recall:         {recall:.4f}\")\n",
    "    print(f\"F1-Score:       {f1:.4f}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'loss': test_loss,\n",
    "        'accuracy': test_acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "print(\"✓ Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b11451",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Experiment 1: Preprocessed Dataset\n",
    "Train on preprocessed public data, test on preprocessed self-collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# EXPERIMENT 1: PREPROCESSED DATASET\")\n",
    "print(\"#\"*60 + \"\\n\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader_prep, val_loader_prep, test_loader_prep = create_dataloaders(\n",
    "    PREPROCESSED_TRAIN,\n",
    "    PREPROCESSED_VAL,\n",
    "    PREPROCESSED_TEST_SELF\n",
    ")\n",
    "\n",
    "# Build model\n",
    "model_prep = build_vit_b16_model()\n",
    "print(f\"\\nModel: Vision Transformer (ViT-B16)\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model_prep.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model_prep.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Train model\n",
    "history_prep = train_model(\n",
    "    model_prep,\n",
    "    train_loader_prep,\n",
    "    val_loader_prep,\n",
    "    model_name='vit_b16_preprocessed',\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_prep['train_acc'], label='Train Accuracy')\n",
    "axes[0].plot(history_prep['val_acc'], label='Val Accuracy')\n",
    "axes[0].set_title('Model Accuracy - Preprocessed')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_prep['train_loss'], label='Train Loss')\n",
    "axes[1].plot(history_prep['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss - Preprocessed')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "results_prep = evaluate_model(model_prep, test_loader_prep, \"ViT-B16 - Preprocessed\")\n",
    "\n",
    "# Log results\n",
    "log_result(\n",
    "    model_name='ViT-B16',\n",
    "    experiment_type='Preprocessed',\n",
    "    accuracy=results_prep['accuracy'],\n",
    "    precision=results_prep['precision'],\n",
    "    recall=results_prep['recall'],\n",
    "    f1=results_prep['f1'],\n",
    "    loss=results_prep['loss']\n",
    ")\n",
    "\n",
    "print(\"✓ Experiment 1 completed and results logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb5a40c",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Experiment 2: Raw Dataset\n",
    "Train on raw public data, test on raw self-collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db642a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# EXPERIMENT 2: RAW DATASET\")\n",
    "print(\"#\"*60 + \"\\n\")\n",
    "\n",
    "# For raw data, we'll use 80-20 split for train-val from RAW_PUBLIC\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Load full raw public dataset\n",
    "raw_public_dataset = datasets.ImageFolder(RAW_PUBLIC, transform=train_transform)\n",
    "train_size = int(0.8 * len(raw_public_dataset))\n",
    "val_size = len(raw_public_dataset) - train_size\n",
    "train_dataset_raw, val_dataset_raw = random_split(\n",
    "    raw_public_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Update validation dataset transform\n",
    "val_dataset_raw.dataset.transform = val_test_transform\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset_raw = datasets.ImageFolder(RAW_SELF, transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader_raw = DataLoader(\n",
    "    train_dataset_raw, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "val_loader_raw = DataLoader(\n",
    "    val_dataset_raw, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "test_loader_raw = DataLoader(\n",
    "    test_dataset_raw, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset sizes:\")\n",
    "print(f\"  Training:   {len(train_dataset_raw)} images\")\n",
    "print(f\"  Validation: {len(val_dataset_raw)} images\")\n",
    "print(f\"  Testing:    {len(test_dataset_raw)} images\")\n",
    "\n",
    "# Build new model\n",
    "model_raw = build_vit_b16_model()\n",
    "\n",
    "# Train model\n",
    "history_raw = train_model(\n",
    "    model_raw,\n",
    "    train_loader_raw,\n",
    "    val_loader_raw,\n",
    "    model_name='vit_b16_raw',\n",
    "    epochs=30\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_raw['train_acc'], label='Train Accuracy')\n",
    "axes[0].plot(history_raw['val_acc'], label='Val Accuracy')\n",
    "axes[0].set_title('Model Accuracy - Raw')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_raw['train_loss'], label='Train Loss')\n",
    "axes[1].plot(history_raw['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss - Raw')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "results_raw = evaluate_model(model_raw, test_loader_raw, \"ViT-B16 - Raw\")\n",
    "\n",
    "# Log results\n",
    "log_result(\n",
    "    model_name='ViT-B16',\n",
    "    experiment_type='Raw',\n",
    "    accuracy=results_raw['accuracy'],\n",
    "    precision=results_raw['precision'],\n",
    "    recall=results_raw['recall'],\n",
    "    f1=results_raw['f1'],\n",
    "    loss=results_raw['loss']\n",
    ")\n",
    "\n",
    "print(\"✓ Experiment 2 completed and results logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b166060",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Comparison Summary\n",
    "Compare results from both experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Experiment': ['Preprocessed', 'Raw'],\n",
    "    'Accuracy': [results_prep['accuracy'], results_raw['accuracy']],\n",
    "    'Precision': [results_prep['precision'], results_raw['precision']],\n",
    "    'Recall': [results_prep['recall'], results_raw['recall']],\n",
    "    'F1-Score': [results_prep['f1'], results_raw['f1']],\n",
    "    'Loss': [results_prep['loss'], results_raw['loss']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VIT-B16 - FINAL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Visualize comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width/2,\n",
    "               [results_prep['accuracy'], results_prep['precision'],\n",
    "                results_prep['recall'], results_prep['f1']],\n",
    "               width, label='Preprocessed')\n",
    "bars2 = ax.bar(x + width/2,\n",
    "               [results_raw['accuracy'], results_raw['precision'],\n",
    "                results_raw['recall'], results_raw['f1']],\n",
    "               width, label='Raw')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('ViT-B16: Preprocessed vs Raw Dataset')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ All experiments completed successfully!\")\n",
    "print(\"✓ Models saved in 'models/' directory\")\n",
    "print(\"✓ Results logged to 'final_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

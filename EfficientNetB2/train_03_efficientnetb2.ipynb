{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d42ec9d",
   "metadata": {},
   "source": [
    "# EfficientNetB2 - Waste Classification\n",
    "## TensorFlow Implementation (Windows/CUDA)\n",
    "\n",
    "**Model:** EfficientNetB2 (ImageNet pretrained)\n",
    "\n",
    "**Objective:** Compare performance between preprocessed and raw datasets\n",
    "\n",
    "**Hardware:** Windows RTX 3060 Ti (CUDA)\n",
    "\n",
    "**Classes:** aluminium, paper, plastic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd7196",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3bee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow==2.20.0 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (26.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (70.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (2.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (1.76.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.10.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (3.13.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (3.15.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting nvidia-cublas-cu12<13.0,>=12.5.3.2 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_cublas_cu12-12.9.1.4-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.9.79-py3-none-manylinux_2_25_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.9.79-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12<10.0,>=9.3.0.75 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_cudnn_cu12-9.18.1.3-py3-none-manylinux_2_27_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting nvidia-cufft-cu12<12.0,>=11.2.3.61 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_cufft_cu12-11.4.1.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-curand-cu12<11.0,>=10.3.6.82 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_curand_cu12-10.3.10.19-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12<12.0,>=11.6.3.83 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.5.82-py3-none-manylinux_2_27_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting nvidia-cusparse-cu12<13.0,>=12.5.1.3 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.10.65-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nccl-cu12<3.0,>=2.25.1 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvjitlink-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (2026.1.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (3.10.1)\n",
      "Requirement already satisfied: pillow in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (12.0.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (3.1.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (0.46.3)\n",
      "Requirement already satisfied: rich in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (14.3.2)\n",
      "Requirement already satisfied: namex in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (0.1.0)\n",
      "Requirement already satisfied: optree in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /mnt/c/laragon/www/CV-project/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow==2.20.0->tensorflow[and-cuda]==2.20.0) (0.1.2)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "Using cached ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "Using cached nvidia_cublas_cu12-12.9.1.4-py3-none-manylinux_2_27_x86_64.whl (581.2 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.9.79-py3-none-manylinux_2_25_x86_64.whl (10.8 MB)\n",
      "Using cached nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.5 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (89.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.9.79-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "Downloading nvidia_cudnn_cu12-9.18.1.3-py3-none-manylinux_2_27_x86_64.whl (648.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m648.6/648.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m  \u001b[33m0:00:53\u001b[0mm0:00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hUsing cached nvidia_cufft_cu12-11.4.1.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.9 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.10.19-py3-none-manylinux_2_27_x86_64.whl (68.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.5.82-py3-none-manylinux_2_27_x86_64.whl (338.1 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.10.65-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (366.5 MB)\n",
      "Downloading nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl (289.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m289.8/289.8 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m  \u001b[33m0:00:23\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Downloading protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow 2.20.0 GPU version for Windows CUDA 12.7\n",
    "# TensorFlow 2.20.0 supports CUDA 12.7\n",
    "!pip uninstall -y tensorflow\n",
    "!pip install tensorflow[and-cuda]==2.20.0\n",
    "\n",
    "# Alternative manual installation if GPU doesn't work:\n",
    "# !pip install tensorflow==2.20.0\n",
    "# !pip install nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 nvidia-cublas-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d062d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 02:37:18.897183: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-02 02:37:20.118448: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-02 02:37:26.907487: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "GPU Available: []\n",
      "CUDA Available: True\n",
      "‚ùå GPU not available. Check CUDA installation.\n",
      "üí° Windows Troubleshooting:\n",
      "   1. Install CUDA 12.0+ toolkit from NVIDIA website\n",
      "   2. Install cuDNN 8.9+ compatible with CUDA 12.x\n",
      "   3. Add CUDA bin path to Windows PATH\n",
      "   4. Restart VS Code/Jupyter after installation\n",
      "   5. Try: pip install nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 02:37:39.876039: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-02 02:37:39.932488: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Import custom logger\n",
    "sys.path.append('..')\n",
    "from result_logger import log_result\n",
    "\n",
    "# Check GPU availability and CUDA compatibility\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"CUDA Available:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Additional CUDA check\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"‚úÖ GPU is available and TensorFlow can use it!\")\n",
    "    # Test GPU computation\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        b = tf.constant([[1.0, 0.0], [0.0, 1.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "        print(\"GPU test successful:\", c.numpy())\n",
    "else:\n",
    "    print(\"‚ùå GPU not available. Check CUDA installation.\")\n",
    "    print(\"üí° Windows Troubleshooting:\")\n",
    "    print(\"   1. Install CUDA 12.0+ toolkit from NVIDIA website\")\n",
    "    print(\"   2. Install cuDNN 8.9+ compatible with CUDA 12.x\")\n",
    "    print(\"   3. Add CUDA bin path to Windows PATH\")\n",
    "    print(\"   4. Restart VS Code/Jupyter after installation\")\n",
    "    print(\"   5. Try: pip install nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ccd29b",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Dataset Paths Configuration\n",
    "Define all dataset paths as constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Configuration\n",
    "CLASSES = ['aluminium', 'paper', 'plastic']\n",
    "NUM_CLASSES = 3\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Set A: Preprocessed Public (Training Data)\n",
    "PREPROCESSED_TRAIN = r\"../Dataset/preprocessed_Public/train\"\n",
    "PREPROCESSED_VAL = r\"../Dataset/preprocessed_Public/val\"\n",
    "PREPROCESSED_TEST_PUBLIC = r\"../Dataset/preprocessed_Public/test\"\n",
    "\n",
    "# Set B: Preprocessed Self-Collected (Final Testing)\n",
    "PREPROCESSED_TEST_SELF = r\"../Dataset/preprocessed_self/test\"\n",
    "\n",
    "# Set C: Raw Data (For Comparison)\n",
    "RAW_PUBLIC = r\"../Dataset/Public_dataset\"\n",
    "RAW_SELF = r\"../Dataset/SelfCollected_Dataset\"\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(\"‚úì Paths configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba7a5b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Generators Setup\n",
    "Create data loaders with proper preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af92555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators(train_path, val_path, test_path, use_augmentation=True):\n",
    "    \"\"\"\n",
    "    Create data generators for training, validation, and testing\n",
    "    \n",
    "    Args:\n",
    "        train_path: Path to training data\n",
    "        val_path: Path to validation data (if None, use train_path with validation_split)\n",
    "        test_path: Path to test data\n",
    "        use_augmentation: Whether to apply data augmentation\n",
    "    \n",
    "    Returns:\n",
    "        train_gen, val_gen, test_gen\n",
    "    \"\"\"\n",
    "    \n",
    "    if use_augmentation:\n",
    "        # Training data generator with augmentation\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.2,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input\n",
    "        )\n",
    "    \n",
    "    # Validation and test generators (no augmentation)\n",
    "    val_test_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "    \n",
    "    # Create generators\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        classes=CLASSES\n",
    "    )\n",
    "    \n",
    "    if val_path and os.path.exists(val_path):\n",
    "        val_gen = val_test_datagen.flow_from_directory(\n",
    "            val_path,\n",
    "            target_size=IMG_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False,\n",
    "            classes=CLASSES\n",
    "        )\n",
    "    else:\n",
    "        # Use validation split from training data\n",
    "        val_gen = None\n",
    "    \n",
    "    test_gen = val_test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        classes=CLASSES\n",
    "    )\n",
    "    \n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "print(\"‚úì Data generator function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596005d",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Architecture\n",
    "Build EfficientNetB2 with custom classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnetb2_model():\n",
    "    \"\"\"\n",
    "    Build EfficientNetB2 model with custom classification head\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pretrained EfficientNetB2 (without top classification layer)\n",
    "    base_model = EfficientNetB2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build custom classification head\n",
    "    inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úì Model architecture function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c451ae",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Training Function\n",
    "Complete training pipeline with callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_gen, val_gen, model_name, epochs=30, fine_tune=True):\n",
    "    \"\"\"\n",
    "    Train the model with optional fine-tuning\n",
    "    \n",
    "    Args:\n",
    "        model: Keras model\n",
    "        train_gen: Training data generator\n",
    "        val_gen: Validation data generator\n",
    "        model_name: Name for saving the model\n",
    "        epochs: Number of training epochs\n",
    "        fine_tune: Whether to fine-tune base model layers\n",
    "    \n",
    "    Returns:\n",
    "        Training history\n",
    "    \"\"\"\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            f'models/{model_name}.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Phase 1: Training Classification Head\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Phase 1: Train with frozen base\n",
    "    history_phase1 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=epochs // 2,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    if fine_tune:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training Phase 2: Fine-Tuning Base Model\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Unfreeze base model for fine-tuning\n",
    "        model.layers[1].trainable = True  # base_model\n",
    "        \n",
    "        # Recompile with lower learning rate\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Phase 2: Fine-tune\n",
    "        history_phase2 = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs // 2,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Combine histories\n",
    "        history = history_phase1\n",
    "        for key in history_phase1.history.keys():\n",
    "            history.history[key].extend(history_phase2.history[key])\n",
    "    else:\n",
    "        history = history_phase1\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"‚úì Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36bd31f",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Evaluation Function\n",
    "Evaluate model and generate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_gen, experiment_name):\n",
    "    \"\"\"\n",
    "    Evaluate model and display results\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        test_gen: Test data generator\n",
    "        experiment_name: Name of the experiment\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating: {experiment_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Get predictions\n",
    "    test_gen.reset()\n",
    "    y_pred_probs = model.predict(test_gen, verbose=1)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = test_gen.classes\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss, test_acc = model.evaluate(test_gen, verbose=0)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASSES))\n",
    "    \n",
    "    # Display confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "    plt.title(f'Confusion Matrix - {experiment_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Results Summary - {experiment_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Test Loss:      {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy:  {test_acc:.4f}\")\n",
    "    print(f\"Precision:      {precision:.4f}\")\n",
    "    print(f\"Recall:         {recall:.4f}\")\n",
    "    print(f\"F1-Score:       {f1:.4f}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'loss': test_loss,\n",
    "        'accuracy': test_acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "print(\"‚úì Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e18ec",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Experiment 1: Preprocessed Dataset\n",
    "Train on preprocessed public data, test on preprocessed self-collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# EXPERIMENT 1: PREPROCESSED DATASET\")\n",
    "print(\"#\"*60 + \"\\n\")\n",
    "\n",
    "# Create data generators\n",
    "train_gen_prep, val_gen_prep, test_gen_prep = create_data_generators(\n",
    "    PREPROCESSED_TRAIN,\n",
    "    PREPROCESSED_VAL,\n",
    "    PREPROCESSED_TEST_SELF,\n",
    "    use_augmentation=True\n",
    ")\n",
    "\n",
    "# Build model\n",
    "model_prep = build_efficientnetb2_model()\n",
    "print(\"\\nModel Summary:\")\n",
    "model_prep.summary()\n",
    "\n",
    "# Train model\n",
    "history_prep = train_model(\n",
    "    model_prep,\n",
    "    train_gen_prep,\n",
    "    val_gen_prep,\n",
    "    model_name='efficientnetb2_preprocessed',\n",
    "    epochs=30,\n",
    "    fine_tune=True\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_prep.history['accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history_prep.history['val_accuracy'], label='Val Accuracy')\n",
    "axes[0].set_title('Model Accuracy - Preprocessed')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_prep.history['loss'], label='Train Loss')\n",
    "axes[1].plot(history_prep.history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss - Preprocessed')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "results_prep = evaluate_model(model_prep, test_gen_prep, \"EfficientNetB2 - Preprocessed\")\n",
    "\n",
    "# Log results\n",
    "log_result(\n",
    "    model_name='EfficientNetB2',\n",
    "    experiment_type='Preprocessed',\n",
    "    accuracy=results_prep['accuracy'],\n",
    "    precision=results_prep['precision'],\n",
    "    recall=results_prep['recall'],\n",
    "    f1=results_prep['f1'],\n",
    "    loss=results_prep['loss']\n",
    ")\n",
    "\n",
    "print(\"‚úì Experiment 1 completed and results logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee11ebd",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Experiment 2: Raw Dataset\n",
    "Train on raw public data, test on raw self-collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# EXPERIMENT 2: RAW DATASET\")\n",
    "print(\"#\"*60 + \"\\n\")\n",
    "\n",
    "# Create data generators for raw data\n",
    "train_gen_raw, _, test_gen_raw = create_data_generators(\n",
    "    RAW_PUBLIC,\n",
    "    None,  # No separate validation, will use validation_split\n",
    "    RAW_SELF,\n",
    "    use_augmentation=True\n",
    ")\n",
    "\n",
    "# Create validation generator from training data\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen_raw = val_datagen.flow_from_directory(\n",
    "    RAW_PUBLIC,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    classes=CLASSES,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_gen_raw = val_datagen.flow_from_directory(\n",
    "    RAW_PUBLIC,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=CLASSES,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Build new model\n",
    "model_raw = build_efficientnetb2_model()\n",
    "\n",
    "# Train model\n",
    "history_raw = train_model(\n",
    "    model_raw,\n",
    "    train_gen_raw,\n",
    "    val_gen_raw,\n",
    "    model_name='efficientnetb2_raw',\n",
    "    epochs=30,\n",
    "    fine_tune=True\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_raw.history['accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history_raw.history['val_accuracy'], label='Val Accuracy')\n",
    "axes[0].set_title('Model Accuracy - Raw')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_raw.history['loss'], label='Train Loss')\n",
    "axes[1].plot(history_raw.history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss - Raw')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "results_raw = evaluate_model(model_raw, test_gen_raw, \"EfficientNetB2 - Raw\")\n",
    "\n",
    "# Log results\n",
    "log_result(\n",
    "    model_name='EfficientNetB2',\n",
    "    experiment_type='Raw',\n",
    "    accuracy=results_raw['accuracy'],\n",
    "    precision=results_raw['precision'],\n",
    "    recall=results_raw['recall'],\n",
    "    f1=results_raw['f1'],\n",
    "    loss=results_raw['loss']\n",
    ")\n",
    "\n",
    "print(\"‚úì Experiment 2 completed and results logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5262244",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Comparison Summary\n",
    "Compare results from both experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Experiment': ['Preprocessed', 'Raw'],\n",
    "    'Accuracy': [results_prep['accuracy'], results_raw['accuracy']],\n",
    "    'Precision': [results_prep['precision'], results_raw['precision']],\n",
    "    'Recall': [results_prep['recall'], results_raw['recall']],\n",
    "    'F1-Score': [results_prep['f1'], results_raw['f1']],\n",
    "    'Loss': [results_prep['loss'], results_raw['loss']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EFFICIENTNETB2 - FINAL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Visualize comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width/2, \n",
    "               [results_prep['accuracy'], results_prep['precision'], \n",
    "                results_prep['recall'], results_prep['f1']], \n",
    "               width, label='Preprocessed')\n",
    "bars2 = ax.bar(x + width/2, \n",
    "               [results_raw['accuracy'], results_raw['precision'], \n",
    "                results_raw['recall'], results_raw['f1']], \n",
    "               width, label='Raw')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('EfficientNetB2: Preprocessed vs Raw Dataset')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì All experiments completed successfully!\")\n",
    "print(\"‚úì Models saved in 'models/' directory\")\n",
    "print(\"‚úì Results logged to 'final_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
